{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.autograd import grad\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "# Neural network architecture (LeNet with BatchNorm)\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(6) \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(16) \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# CIFAR-10 dataset and define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "train_data = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# noise level\n",
    "NOISE_LEVEL = 0.99\n",
    "\n",
    "stored_noise = []\n",
    "\n",
    "# Add Gaussian noise to gradients and store the noise\n",
    "def add_and_store_noise_to_gradients(gradients, noise_level, store_noise=False):\n",
    "    noisy_gradients = []\n",
    "    for g in gradients:\n",
    "        noise = torch.randn_like(g) * noise_level\n",
    "        if store_noise:\n",
    "            stored_noise.append(noise)\n",
    "        noisy_gradients.append(g + noise)\n",
    "    return noisy_gradients\n",
    "\n",
    "#Train the model\n",
    "def train(model, train_loader, optimizer, criterion, device, scheduler, add_noise=False):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for epoch in range(10):\n",
    "        scheduler.step()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            if add_noise:\n",
    "                # Add Gaussian noise to gradients and store the noise\n",
    "                noisy_gradients = add_and_store_noise_to_gradients([p.grad for p in model.parameters()], NOISE_LEVEL, store_noise=True)\n",
    "                for p, noisy_grad in zip(model.parameters(), noisy_gradients):\n",
    "                    p.grad = noisy_grad\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if batch_idx % 200 == 199:\n",
    "                print(f\"Epoch [{epoch + 1}/10], Batch {batch_idx + 1}/{len(train_loader)}, Loss: {running_loss / 200:.4f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "# Test the model\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    accuracy = 100.0 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# DLG attack and image reconstruction\n",
    "def perform_dlg_attack(model, criterion, test_loader, device, add_noise=False):\n",
    "    model.eval()\n",
    "    #batch selected for image reconstruction\n",
    "    img_batch_index = 0\n",
    "    original_images = []\n",
    "    reconstructed_images = []\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if batch_idx == img_batch_index:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            original_images.append(data.cpu().detach())\n",
    "\n",
    "            # Forward pass to get the loss and gradients\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            gradients = [p.grad.clone() for p in model.parameters()]\n",
    "\n",
    "            if add_noise:\n",
    "                noisy_gradients = [g + n for g, n in zip(gradients, stored_noise)]\n",
    "                # Reconstruction with noisy gradients\n",
    "                reconstructed_data = reconstruct_from_gradients(model, noisy_gradients, data, target, device, criterion)\n",
    "            else:\n",
    "                # Reconstruction without noise\n",
    "                reconstructed_data = reconstruct_from_gradients(model, gradients, data, target, device, criterion)\n",
    "            \n",
    "            reconstructed_images.append(reconstructed_data.cpu().detach())\n",
    "            break \n",
    "\n",
    "    # Plot original and reconstructed images\n",
    "    plot_images(original_images[0], reconstructed_images[0])\n",
    "\n",
    "def reconstruct_from_gradients(model, gradients, data, target, device, criterion):\n",
    "    reconstructed_data = data.clone().to(device).requires_grad_(True)\n",
    "    optimizer = torch.optim.LBFGS([reconstructed_data])\n",
    "    for _ in range(10):\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            output = model(reconstructed_data)\n",
    "            loss = criterion(output, target)\n",
    "            reconstructed_gradients = grad(loss, model.parameters(), create_graph=True)\n",
    "            # Compute loss based on the difference between noisy gradients and current gradients\n",
    "            gradient_diff_loss = 0\n",
    "            for rg, ng in zip(reconstructed_gradients, gradients):\n",
    "                gradient_diff_loss += ((rg - ng)**2).sum()\n",
    "            gradient_diff_loss.backward()\n",
    "            return gradient_diff_loss\n",
    "        optimizer.step(closure)\n",
    "    return reconstructed_data\n",
    "\n",
    "def plot_images(original_images, reconstructed_images):\n",
    "    to_pil = ToPILImage()\n",
    "\n",
    "    def reverse_normalize(tensor):\n",
    "        return torch.clamp(tensor * 0.5 + 0.5, 0, 1)\n",
    "\n",
    "    batch_size = len(original_images)\n",
    "    fig, axes = plt.subplots(nrows=batch_size, ncols=2, figsize=(10, 5 * batch_size))\n",
    "    for i in range(batch_size):\n",
    "        # Reverse normalization and convert tensors to PIL images for better readability\n",
    "        original_image = to_pil(reverse_normalize(original_images[i]))\n",
    "        reconstructed_image = to_pil(reverse_normalize(reconstructed_images[i]))\n",
    "        axes[i, 0].imshow(original_image)\n",
    "        axes[i, 0].set_title(f'Original Image {i + 1}')\n",
    "        axes[i, 0].axis('off')\n",
    "        axes[i, 1].imshow(reconstructed_image)\n",
    "        axes[i, 1].set_title(f'Reconstructed Image {i + 1}')\n",
    "        axes[i, 1].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Initialize the model, optimizer, and criterion\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LeNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Set up learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)  # Reduce LR by half every 5 epochs\n",
    "\n",
    "# Train the model without noise\n",
    "print(\"Training the model without noise...\")\n",
    "train(model, train_loader, optimizer, criterion, device, scheduler, add_noise=False)\n",
    "\n",
    "# Test the model without noise\n",
    "print(\"\\nTesting the model without noise...\")\n",
    "test_accuracy = test(model, test_loader, device)\n",
    "\n",
    "# Perform DLG attack and image reconstruction without noise\n",
    "print(\"\\nPerforming DLG attack and reconstruction without noise...\")\n",
    "perform_dlg_attack(model, criterion, test_loader, device, add_noise=False)\n",
    "\n",
    "# Train the model with noise\n",
    "print(\"\\nTraining the model with noise...\")\n",
    "train(model, train_loader, optimizer, criterion, device, scheduler, add_noise=True)\n",
    "\n",
    "# Test the model with noise\n",
    "print(\"\\nTesting the model with noise...\")\n",
    "test_accuracy = test(model, test_loader, device)\n",
    "\n",
    "# Perform DLG attack and  image reconstruction with noise\n",
    "print(\"\\nPerforming DLG attack and reconstruction with noise...\")\n",
    "perform_dlg_attack(model, criterion, test_loader, device, add_noise=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
